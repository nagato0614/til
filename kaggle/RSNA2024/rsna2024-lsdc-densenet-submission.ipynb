{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 71549,
     "databundleVersionId": 8561470,
     "sourceType": "competition"
    },
    {
     "sourceId": 8727685,
     "sourceType": "datasetVersion",
     "datasetId": 5236783
    }
   ],
   "dockerImageVersionId": 30733,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# RSNA2024 LSDC Submission Baseline\nThis notebook is forked [here](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline). In the [previous notebook](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-making-dataset), the author selected the images we wanted to use and exported them to png.The original notebook training. And the original other trained EfficientNet_B4 model with these images. \n\nI desided to change the model to see if there is any improvement. The reason why I choose DenseNet201 for training is that DenseNet201 has generally same number of parameters and size with EfficientNet_B4 so that I believe that Kaggle GPU could handle it and we don't need extra machine.\n\n### My other Notebooks\n- [RSNA2024 LSDC Making Dataset](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-making-dataset) \n- [RSNA2024 LSDC Training DenseNet](https://www.kaggle.com/code/hugowjd/rsna2024-lsdc-training-densenet) \n- [RSNA2024 LSDC Submission DenseNet](https://www.kaggle.com/code/hugowjd/rsna2024-lsdc-densenet-submission) <- you're reading now\n\n### Reference:\n* [Huang, G., Liu, Z., Van Der Maaten, L., and Weinberger, K. Q. Densely connected convolutional networks. CVPR, 2017.](https://arxiv.org/abs/1608.06993)\n* [Mingxing Tan and Quoc V. Le. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. ICML 2019.](https://arxiv.org/abs/1905.11946)\n\n### Future Improvement\n* I'm certain that we can run other models to train these images. We can do it by changing ***MODEL_NAME*** parameters in **Config** session. I would list some CNN models which are suitable for image classification and these numbers of parameters.\n  * ResNet:\n    * ResNet-18: ~11.7 million parameters\n    * **ResNet-34: ~21.8 million parameters**\n    * **ResNet-50: ~25.6 million parameters**\n    * ResNet-101: ~44.5 million parameters\n    * ResNet-152: ~60 million parameters\n  * VGG:\n    * VGG-16: ~138 million parameters\n    * VGG-19: ~143 million parameters\n  * Inception Networks:\n    * Inception v1 (GoogleNet): ~6.8 million parameters\n    * Inception v3: ~23.8 million parameters\n  * DenseNet:\n    * DenseNet-121: ~8 million parameters\n    * **DenseNet-169: ~14 million parameters**\n        * TODO: current plan\n    * **DenseNet-201: ~20 million parameters** \n        * My Submission LB: 0.61\n        * [10 folds submission LB](https://www.kaggle.com/code/sadidul012/densenet201-submission): 0.6\n    * DenseNet-264: ~33 million parameters\n  * MobileNets (parameters can vary significantly with changes in alpha and resolution multipliers):\n    * MobileNetV1 (1.0 224): ~4.2 million parameters\n    * MobileNetV2 (1.0 224): ~3.5 million parameters\n    * MobileNetV3 Large: ~5.4 million parameters\n  * Vision Transformers (ViT):\n    * ViT-B/16 (base model with patch size 16x16): ~86 million parameters\n  * Xception:\n    * **Xception: ~22.9 million parameters**\n        * my test LB : 0.66\n  * EfficientNet\n    * EfficientNet-B0: ~5.3 million parameters\n    * EfficientNet-B1: ~7.8 million parameters\n    * EfficientNet-B2: ~9.2 million parameters\n        * [EFNetV2 LB](https://www.kaggle.com/code/shubhamcodez/rsna-efficientnet-starter-notebook): 1.01 \n    * EfficientNet-B3: ~12 million parameters\n        * [Original Notebook](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline) LB: 0.69\n    * **EfficientNet-B4: ~19 million parameters**\n        * [Original Notebook](https://www.kaggle.com/code/itsuki9180/rsna2024-lsdc-submission-baseline) LB: 0.70\n    * EfficientNet-B5: ~30 million parameters\n    * EfficientNet-B6: ~43 million parameters\n    * EfficientNet-B7: ~66 million parameters\n* The original author said that we can improve the dataset making process\n* I only trained 5 **folds** and 10 **epochs**, you can modify these parameters. But take care of overfitting.",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Import Libralies",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\nimport gc\nimport sys\nfrom PIL import Image\nimport cv2\nimport math, random\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\n\nfrom collections import OrderedDict\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import AdamW\n\nimport timm\nfrom timm.utils import ModelEmaV2\nfrom transformers import get_cosine_schedule_with_warmup\n\nimport albumentations as A\n\nfrom sklearn.model_selection import KFold\n\nimport re\nimport pydicom",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:44.881509Z",
     "iopub.execute_input": "2024-06-25T10:55:44.882285Z",
     "iopub.status.idle": "2024-06-25T10:55:53.197448Z",
     "shell.execute_reply.started": "2024-06-25T10:55:44.882253Z",
     "shell.execute_reply": "2024-06-25T10:55:53.196657Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:47:51.514947Z",
     "start_time": "2024-06-25T12:47:49.587710Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.199232Z",
     "iopub.execute_input": "2024-06-25T10:55:53.200261Z",
     "iopub.status.idle": "2024-06-25T10:55:53.204223Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.200225Z",
     "shell.execute_reply": "2024-06-25T10:55:53.203337Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:47:51.517582Z",
     "start_time": "2024-06-25T12:47:51.515982Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "# Config",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "DENSENET_DIR = f'/kaggle/input/densenet-weights-for-rsna-2024/'\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nN_WORKERS = os.cpu_count()\nUSE_AMP = True\nSEED = 8620\n\nIMG_SIZE = [512, 512]\nIN_CHANS = 30\nN_LABELS = 25\nN_CLASSES = 3 * N_LABELS\n\nN_FOLDS = 5\n\n# MODEL_NAME = \"tf_efficientnet_b4.ns_jft_in1k\"\nDENSE_MODEL_NAME = \"densenet201\"\nBATCH_SIZE = 1",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.205293Z",
     "iopub.execute_input": "2024-06-25T10:55:53.205543Z",
     "iopub.status.idle": "2024-06-25T10:55:53.238183Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.205521Z",
     "shell.execute_reply": "2024-06-25T10:55:53.237292Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:47:51.520171Z",
     "start_time": "2024-06-25T12:47:51.518135Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# rd = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "rd = '/Volumes/SSD/rsna-2024-lumbar-spine-degenerative-classification'\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.240275Z",
     "iopub.execute_input": "2024-06-25T10:55:53.241153Z",
     "iopub.status.idle": "2024-06-25T10:55:53.252646Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.241119Z",
     "shell.execute_reply": "2024-06-25T10:55:53.251443Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:06.363529Z",
     "start_time": "2024-06-25T12:48:06.361798Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\ndevice",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.253906Z",
     "iopub.execute_input": "2024-06-25T10:55:53.254715Z",
     "iopub.status.idle": "2024-06-25T10:55:53.263765Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.254683Z",
     "shell.execute_reply": "2024-06-25T10:55:53.262926Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:06.825263Z",
     "start_time": "2024-06-25T12:48:06.822591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_csv(f'{rd}/test_series_descriptions.csv')\ndf.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.264943Z",
     "iopub.execute_input": "2024-06-25T10:55:53.265477Z",
     "iopub.status.idle": "2024-06-25T10:55:53.298581Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.265446Z",
     "shell.execute_reply": "2024-06-25T10:55:53.297843Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:07.040342Z",
     "start_time": "2024-06-25T12:48:07.034234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   study_id   series_id series_description\n",
       "0  44036939  2828203845        Sagittal T1\n",
       "1  44036939  3481971518           Axial T2\n",
       "2  44036939  3844393089   Sagittal T2/STIR"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939</td>\n",
       "      <td>2828203845</td>\n",
       "      <td>Sagittal T1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939</td>\n",
       "      <td>3481971518</td>\n",
       "      <td>Axial T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939</td>\n",
       "      <td>3844393089</td>\n",
       "      <td>Sagittal T2/STIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "study_ids = list(df['study_id'].unique())",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.299783Z",
     "iopub.execute_input": "2024-06-25T10:55:53.300148Z",
     "iopub.status.idle": "2024-06-25T10:55:53.306860Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.300117Z",
     "shell.execute_reply": "2024-06-25T10:55:53.305857Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:07.214927Z",
     "start_time": "2024-06-25T12:48:07.212881Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "sample_sub = pd.read_csv(f'{rd}/sample_submission.csv')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.308030Z",
     "iopub.execute_input": "2024-06-25T10:55:53.308352Z",
     "iopub.status.idle": "2024-06-25T10:55:53.323135Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.308321Z",
     "shell.execute_reply": "2024-06-25T10:55:53.322165Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:07.384231Z",
     "start_time": "2024-06-25T12:48:07.380746Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": "LABELS = list(sample_sub.columns[1:])\nLABELS",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.324209Z",
     "iopub.execute_input": "2024-06-25T10:55:53.324497Z",
     "iopub.status.idle": "2024-06-25T10:55:53.330548Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.324471Z",
     "shell.execute_reply": "2024-06-25T10:55:53.329442Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:07.544931Z",
     "start_time": "2024-06-25T12:48:07.541905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normal_mild', 'moderate', 'severe']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "LEVELS = [\n",
    "    'l1_l2',\n",
    "    'l2_l3',\n",
    "    'l3_l4',\n",
    "    'l4_l5',\n",
    "    'l5_s1',\n",
    "]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.334305Z",
     "iopub.execute_input": "2024-06-25T10:55:53.334641Z",
     "iopub.status.idle": "2024-06-25T10:55:53.339611Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.334608Z",
     "shell.execute_reply": "2024-06-25T10:55:53.338655Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:07.943743Z",
     "start_time": "2024-06-25T12:48:07.940485Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.340888Z",
     "iopub.execute_input": "2024-06-25T10:55:53.341238Z",
     "iopub.status.idle": "2024-06-25T10:55:53.348645Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.341191Z",
     "shell.execute_reply": "2024-06-25T10:55:53.347791Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:08.390831Z",
     "start_time": "2024-06-25T12:48:08.388659Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": "# Define Dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class RSNA24TestDataset(Dataset):\n",
    "    def __init__(self, df, study_ids, phase='test', transform=None):\n",
    "        self.df = df\n",
    "        self.study_ids = study_ids\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "    \n",
    "    def get_img_paths(self, study_id, series_desc):\n",
    "        pdf = self.df[self.df['study_id']==study_id]\n",
    "        pdf_ = pdf[pdf['series_description']==series_desc]\n",
    "        allimgs = []\n",
    "        for i, row in pdf_.iterrows():\n",
    "            pimgs = glob.glob(f'{rd}/test_images/{study_id}/{row[\"series_id\"]}/*.dcm')\n",
    "            pimgs = sorted(pimgs, key=natural_keys)\n",
    "            allimgs.extend(pimgs)\n",
    "            \n",
    "        return allimgs\n",
    "    \n",
    "    def read_dcm_ret_arr(self, src_path):\n",
    "        dicom_data = pydicom.dcmread(src_path)\n",
    "        image = dicom_data.pixel_array\n",
    "        image = (image - image.min()) / (image.max() - image.min() + 1e-6) * 255\n",
    "        img = cv2.resize(image, (IMG_SIZE[0], IMG_SIZE[1]),interpolation=cv2.INTER_CUBIC)\n",
    "        assert img.shape==(IMG_SIZE[0], IMG_SIZE[1])\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = np.zeros((IMG_SIZE[0], IMG_SIZE[1], IN_CHANS), dtype=np.uint8)\n",
    "        st_id = self.study_ids[idx]        \n",
    "        \n",
    "        # Sagittal T1\n",
    "        allimgs_st1 = self.get_img_paths(st_id, 'Sagittal T1')\n",
    "        if len(allimgs_st1)==0:\n",
    "            print(st_id, ': Sagittal T1, has no images')\n",
    "        \n",
    "        else:\n",
    "            step = len(allimgs_st1) / 10.0\n",
    "            st = len(allimgs_st1)/2.0 - 4.0*step\n",
    "            end = len(allimgs_st1)+0.0001\n",
    "            for j, i in enumerate(np.arange(st, end, step)):\n",
    "                try:\n",
    "                    ind2 = max(0, int((i-0.5001).round()))\n",
    "                    img = self.read_dcm_ret_arr(allimgs_st1[ind2])\n",
    "                    x[..., j] = img.astype(np.uint8)\n",
    "                except:\n",
    "                    print(f'failed to load on {st_id}, Sagittal T1')\n",
    "                    pass\n",
    "            \n",
    "        # Sagittal T2/STIR\n",
    "        allimgs_st2 = self.get_img_paths(st_id, 'Sagittal T2/STIR')\n",
    "        if len(allimgs_st2)==0:\n",
    "            print(st_id, ': Sagittal T2/STIR, has no images')\n",
    "            \n",
    "        else:\n",
    "            step = len(allimgs_st2) / 10.0\n",
    "            st = len(allimgs_st2)/2.0 - 4.0*step\n",
    "            end = len(allimgs_st2)+0.0001\n",
    "            for j, i in enumerate(np.arange(st, end, step)):\n",
    "                try:\n",
    "                    ind2 = max(0, int((i-0.5001).round()))\n",
    "                    img = self.read_dcm_ret_arr(allimgs_st2[ind2])\n",
    "                    x[..., j+10] = img.astype(np.uint8)\n",
    "                except:\n",
    "                    print(f'failed to load on {st_id}, Sagittal T2/STIR')\n",
    "                    pass\n",
    "            \n",
    "        # Axial T2\n",
    "        allimgs_at2 = self.get_img_paths(st_id, 'Axial T2')\n",
    "        if len(allimgs_at2)==0:\n",
    "            print(st_id, ': Axial T2, has no images')\n",
    "            \n",
    "        else:\n",
    "            step = len(allimgs_at2) / 10.0\n",
    "            st = len(allimgs_at2)/2.0 - 4.0*step\n",
    "            end = len(allimgs_at2)+0.0001\n",
    "\n",
    "            for j, i in enumerate(np.arange(st, end, step)):\n",
    "                try:\n",
    "                    ind2 = max(0, int((i-0.5001).round()))\n",
    "                    img = self.read_dcm_ret_arr(allimgs_at2[ind2])\n",
    "                    x[..., j+20] = img.astype(np.uint8)\n",
    "                except:\n",
    "                    print(f'failed to load on {st_id}, Axial T2')\n",
    "                    pass  \n",
    "            \n",
    "            \n",
    "        if self.transform is not None:\n",
    "            x = self.transform(image=x)['image']\n",
    "\n",
    "        x = x.transpose(2, 0, 1)\n",
    "                \n",
    "        return x, str(st_id)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.349919Z",
     "iopub.execute_input": "2024-06-25T10:55:53.350192Z",
     "iopub.status.idle": "2024-06-25T10:55:53.370850Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.350171Z",
     "shell.execute_reply": "2024-06-25T10:55:53.369935Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:09.213149Z",
     "start_time": "2024-06-25T12:48:09.205548Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": "transforms_test = A.Compose([\n    A.Resize(IMG_SIZE[0], IMG_SIZE[1]),\n    A.Normalize(mean=0.5, std=0.5)\n])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.372086Z",
     "iopub.execute_input": "2024-06-25T10:55:53.372332Z",
     "iopub.status.idle": "2024-06-25T10:55:53.381963Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.372297Z",
     "shell.execute_reply": "2024-06-25T10:55:53.381157Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:09.877696Z",
     "start_time": "2024-06-25T12:48:09.874998Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "test_ds = RSNA24TestDataset(df, study_ids, transform=transforms_test)\n",
    "test_dl = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=1, \n",
    "    shuffle=False,\n",
    "    num_workers=N_WORKERS,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.382876Z",
     "iopub.execute_input": "2024-06-25T10:55:53.383151Z",
     "iopub.status.idle": "2024-06-25T10:55:53.391737Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.383128Z",
     "shell.execute_reply": "2024-06-25T10:55:53.390900Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:10.240031Z",
     "start_time": "2024-06-25T12:48:10.237248Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T12:51:51.790122Z",
     "start_time": "2024-06-25T12:51:49.614602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# データを一つ取り出してshapeを確認\n",
    "for x, st_id in test_dl:\n",
    "    print(f'study_id: {st_id}, shape: {x.shape}')\n",
    "    break  # 一つだけ確認するためにループを抜ける"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 31463) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1131\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1130\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1131\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    112\u001B[0m timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Empty\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/connection.py:424\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 424\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:67\u001B[0m, in \u001B[0;36m_set_SIGCHLD_handler.<locals>.handler\u001B[0;34m(signum, frame)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandler\u001B[39m(signum, frame):\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001B[39;00m\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;66;03m# Python can still get and update the process status successfully.\u001B[39;00m\n\u001B[0;32m---> 67\u001B[0m     \u001B[43m_error_if_any_worker_fails\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m previous_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid 31463) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# データを一つ取り出してshapeを確認\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, st_id \u001B[38;5;129;01min\u001B[39;00m test_dl:\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstudy_id: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mst_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m  \u001B[38;5;66;03m# 一つだけ確認するためにループを抜ける\u001B[39;00m\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1328\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1329\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1330\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1293\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1295\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1296\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1297\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1144\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1143\u001B[0m     pids_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(w\u001B[38;5;241m.\u001B[39mpid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[0;32m-> 1144\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpids_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) exited unexpectedly\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue\u001B[38;5;241m.\u001B[39mEmpty):\n\u001B[1;32m   1146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 31463) exited unexpectedly"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": "# Define Model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class RSNA24Model(nn.Module):\n",
    "    def __init__(self, model_name, in_c=30, n_classes=75, pretrained=True, features_only=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\n",
    "                                    model_name,\n",
    "                                    pretrained=pretrained, \n",
    "                                    features_only=features_only,\n",
    "                                    in_chans=in_c,\n",
    "                                    num_classes=n_classes,\n",
    "                                    global_pool='avg'\n",
    "                                    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.model(x)\n",
    "        return y"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.392789Z",
     "iopub.execute_input": "2024-06-25T10:55:53.393110Z",
     "iopub.status.idle": "2024-06-25T10:55:53.401458Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.393078Z",
     "shell.execute_reply": "2024-06-25T10:55:53.400599Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:11.001799Z",
     "start_time": "2024-06-25T12:48:10.999318Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": "# Load Models",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "models = []",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.402441Z",
     "iopub.execute_input": "2024-06-25T10:55:53.402764Z",
     "iopub.status.idle": "2024-06-25T10:55:53.413231Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.402741Z",
     "shell.execute_reply": "2024-06-25T10:55:53.412358Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:11.817810Z",
     "start_time": "2024-06-25T12:48:11.814337Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "import glob\n",
    "DENSE_CKPT_PATHS = glob.glob(f'{DENSENET_DIR}best_wll_model_fold-*.pt')\n",
    "DENSE_CKPT_PATHS = sorted(DENSE_CKPT_PATHS)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.414498Z",
     "iopub.execute_input": "2024-06-25T10:55:53.414886Z",
     "iopub.status.idle": "2024-06-25T10:55:53.428154Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.414857Z",
     "shell.execute_reply": "2024-06-25T10:55:53.427469Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:12.044196Z",
     "start_time": "2024-06-25T12:48:12.041398Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": "for i, cp in enumerate(DENSE_CKPT_PATHS):\n    print(f'loading {cp}...')\n    model = RSNA24Model(DENSE_MODEL_NAME, IN_CHANS, N_CLASSES, pretrained=False)\n    model.load_state_dict(torch.load(cp))\n    model.eval()\n    model.half()\n    model.to(device)\n    models.append(model)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:55:53.429224Z",
     "iopub.execute_input": "2024-06-25T10:55:53.429825Z",
     "iopub.status.idle": "2024-06-25T10:56:01.019114Z",
     "shell.execute_reply.started": "2024-06-25T10:55:53.429776Z",
     "shell.execute_reply": "2024-06-25T10:56:01.018085Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:48:12.274470Z",
     "start_time": "2024-06-25T12:48:12.271113Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": "# Inference loop",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "y_preds = []\n",
    "row_names = []\n",
    "\n",
    "with tqdm(test_dl, leave=True) as pbar:\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, si) in enumerate(pbar):\n",
    "            x = x.to(device)\n",
    "            pred_per_study = np.zeros((25, 3))\n",
    "            \n",
    "            for cond in CONDITIONS:\n",
    "                for level in LEVELS:\n",
    "                    row_names.append(si[0] + '_' + cond + '_' + level)\n",
    "            \n",
    "            for m in models:\n",
    "                y = m(x)[0]\n",
    "                for col in range(N_LABELS):\n",
    "                    pred = y[col*3:col*3+3]\n",
    "                    y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "                    pred_per_study[col] += y_pred / len(models)\n",
    "            y_preds.append(pred_per_study)\n",
    "\n",
    "y_preds = np.concatenate(y_preds, axis=0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:56:01.020546Z",
     "iopub.execute_input": "2024-06-25T10:56:01.020868Z",
     "iopub.status.idle": "2024-06-25T10:56:03.607293Z",
     "shell.execute_reply.started": "2024-06-25T10:56:01.020843Z",
     "shell.execute_reply": "2024-06-25T10:56:03.606107Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T12:51:19.157289Z",
     "start_time": "2024-06-25T12:51:16.818128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "  0%|          | 0/1 [00:02<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/toru/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'RSNA24TestDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 31447) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1131\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1130\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1131\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    112\u001B[0m timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Empty\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/connection.py:424\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 424\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    425\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.13/lib/python3.10/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:67\u001B[0m, in \u001B[0;36m_set_SIGCHLD_handler.<locals>.handler\u001B[0;34m(signum, frame)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhandler\u001B[39m(signum, frame):\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001B[39;00m\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;66;03m# Python can still get and update the process status successfully.\u001B[39;00m\n\u001B[0;32m---> 67\u001B[0m     \u001B[43m_error_if_any_worker_fails\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m previous_handler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid 31447) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(test_dl, leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m----> 6\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m idx, (x, si) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(pbar):\n\u001B[1;32m      7\u001B[0m             x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      8\u001B[0m             pred_per_study \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m25\u001B[39m, \u001B[38;5;241m3\u001B[39m))\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1328\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1329\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1330\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1293\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1295\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1296\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1297\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/project/til/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1144\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(failed_workers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1143\u001B[0m     pids_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mstr\u001B[39m(w\u001B[38;5;241m.\u001B[39mpid) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m failed_workers)\n\u001B[0;32m-> 1144\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDataLoader worker (pid(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpids_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) exited unexpectedly\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, queue\u001B[38;5;241m.\u001B[39mEmpty):\n\u001B[1;32m   1146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: DataLoader worker (pid(s) 31447) exited unexpectedly"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": "# Make Submission",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "sub = pd.DataFrame()\nsub['row_id'] = row_names\nsub[LABELS] = y_preds\nsub.head(25)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:56:03.608734Z",
     "iopub.execute_input": "2024-06-25T10:56:03.609055Z",
     "iopub.status.idle": "2024-06-25T10:56:03.632818Z",
     "shell.execute_reply.started": "2024-06-25T10:56:03.609028Z",
     "shell.execute_reply": "2024-06-25T10:56:03.631863Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": [
    {
     "execution_count": 20,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                             row_id  normal_mild  moderate  \\\n0              44036939_spinal_canal_stenosis_l1_l2     0.452616  0.352106   \n1              44036939_spinal_canal_stenosis_l2_l3     0.197680  0.438134   \n2              44036939_spinal_canal_stenosis_l3_l4     0.163294  0.327955   \n3              44036939_spinal_canal_stenosis_l4_l5     0.220444  0.236467   \n4              44036939_spinal_canal_stenosis_l5_s1     0.819369  0.101085   \n5    44036939_left_neural_foraminal_narrowing_l1_l2     0.568507  0.400318   \n6    44036939_left_neural_foraminal_narrowing_l2_l3     0.382926  0.536820   \n7    44036939_left_neural_foraminal_narrowing_l3_l4     0.258266  0.494966   \n8    44036939_left_neural_foraminal_narrowing_l4_l5     0.151111  0.446989   \n9    44036939_left_neural_foraminal_narrowing_l5_s1     0.203369  0.362533   \n10  44036939_right_neural_foraminal_narrowing_l1_l2     0.586365  0.301689   \n11  44036939_right_neural_foraminal_narrowing_l2_l3     0.414731  0.534636   \n12  44036939_right_neural_foraminal_narrowing_l3_l4     0.202129  0.604219   \n13  44036939_right_neural_foraminal_narrowing_l4_l5     0.174207  0.429858   \n14  44036939_right_neural_foraminal_narrowing_l5_s1     0.234015  0.326340   \n15        44036939_left_subarticular_stenosis_l1_l2     0.379706  0.368691   \n16        44036939_left_subarticular_stenosis_l2_l3     0.156525  0.343565   \n17        44036939_left_subarticular_stenosis_l3_l4     0.082525  0.337474   \n18        44036939_left_subarticular_stenosis_l4_l5     0.064104  0.257596   \n19        44036939_left_subarticular_stenosis_l5_s1     0.300487  0.302523   \n20       44036939_right_subarticular_stenosis_l1_l2     0.363125  0.454164   \n21       44036939_right_subarticular_stenosis_l2_l3     0.154874  0.407927   \n22       44036939_right_subarticular_stenosis_l3_l4     0.085303  0.303296   \n23       44036939_right_subarticular_stenosis_l4_l5     0.065041  0.258260   \n24       44036939_right_subarticular_stenosis_l5_s1     0.308991  0.350569   \n\n      severe  \n0   0.195277  \n1   0.364187  \n2   0.508751  \n3   0.543090  \n4   0.079546  \n5   0.031175  \n6   0.080254  \n7   0.246768  \n8   0.401899  \n9   0.434098  \n10  0.111946  \n11  0.050633  \n12  0.193653  \n13  0.395934  \n14  0.439645  \n15  0.251603  \n16  0.499910  \n17  0.580001  \n18  0.678299  \n19  0.396990  \n20  0.182711  \n21  0.437199  \n22  0.611402  \n23  0.676699  \n24  0.340440  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>normal_mild</th>\n      <th>moderate</th>\n      <th>severe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>44036939_spinal_canal_stenosis_l1_l2</td>\n      <td>0.452616</td>\n      <td>0.352106</td>\n      <td>0.195277</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44036939_spinal_canal_stenosis_l2_l3</td>\n      <td>0.197680</td>\n      <td>0.438134</td>\n      <td>0.364187</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44036939_spinal_canal_stenosis_l3_l4</td>\n      <td>0.163294</td>\n      <td>0.327955</td>\n      <td>0.508751</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44036939_spinal_canal_stenosis_l4_l5</td>\n      <td>0.220444</td>\n      <td>0.236467</td>\n      <td>0.543090</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44036939_spinal_canal_stenosis_l5_s1</td>\n      <td>0.819369</td>\n      <td>0.101085</td>\n      <td>0.079546</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>44036939_left_neural_foraminal_narrowing_l1_l2</td>\n      <td>0.568507</td>\n      <td>0.400318</td>\n      <td>0.031175</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>44036939_left_neural_foraminal_narrowing_l2_l3</td>\n      <td>0.382926</td>\n      <td>0.536820</td>\n      <td>0.080254</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>44036939_left_neural_foraminal_narrowing_l3_l4</td>\n      <td>0.258266</td>\n      <td>0.494966</td>\n      <td>0.246768</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>44036939_left_neural_foraminal_narrowing_l4_l5</td>\n      <td>0.151111</td>\n      <td>0.446989</td>\n      <td>0.401899</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>44036939_left_neural_foraminal_narrowing_l5_s1</td>\n      <td>0.203369</td>\n      <td>0.362533</td>\n      <td>0.434098</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>44036939_right_neural_foraminal_narrowing_l1_l2</td>\n      <td>0.586365</td>\n      <td>0.301689</td>\n      <td>0.111946</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>44036939_right_neural_foraminal_narrowing_l2_l3</td>\n      <td>0.414731</td>\n      <td>0.534636</td>\n      <td>0.050633</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>44036939_right_neural_foraminal_narrowing_l3_l4</td>\n      <td>0.202129</td>\n      <td>0.604219</td>\n      <td>0.193653</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>44036939_right_neural_foraminal_narrowing_l4_l5</td>\n      <td>0.174207</td>\n      <td>0.429858</td>\n      <td>0.395934</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>44036939_right_neural_foraminal_narrowing_l5_s1</td>\n      <td>0.234015</td>\n      <td>0.326340</td>\n      <td>0.439645</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>44036939_left_subarticular_stenosis_l1_l2</td>\n      <td>0.379706</td>\n      <td>0.368691</td>\n      <td>0.251603</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>44036939_left_subarticular_stenosis_l2_l3</td>\n      <td>0.156525</td>\n      <td>0.343565</td>\n      <td>0.499910</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>44036939_left_subarticular_stenosis_l3_l4</td>\n      <td>0.082525</td>\n      <td>0.337474</td>\n      <td>0.580001</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>44036939_left_subarticular_stenosis_l4_l5</td>\n      <td>0.064104</td>\n      <td>0.257596</td>\n      <td>0.678299</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>44036939_left_subarticular_stenosis_l5_s1</td>\n      <td>0.300487</td>\n      <td>0.302523</td>\n      <td>0.396990</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>44036939_right_subarticular_stenosis_l1_l2</td>\n      <td>0.363125</td>\n      <td>0.454164</td>\n      <td>0.182711</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>44036939_right_subarticular_stenosis_l2_l3</td>\n      <td>0.154874</td>\n      <td>0.407927</td>\n      <td>0.437199</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>44036939_right_subarticular_stenosis_l3_l4</td>\n      <td>0.085303</td>\n      <td>0.303296</td>\n      <td>0.611402</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>44036939_right_subarticular_stenosis_l4_l5</td>\n      <td>0.065041</td>\n      <td>0.258260</td>\n      <td>0.676699</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>44036939_right_subarticular_stenosis_l5_s1</td>\n      <td>0.308991</td>\n      <td>0.350569</td>\n      <td>0.340440</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "sub.to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-25T10:56:03.634141Z",
     "iopub.execute_input": "2024-06-25T10:56:03.634627Z",
     "iopub.status.idle": "2024-06-25T10:56:03.655932Z",
     "shell.execute_reply.started": "2024-06-25T10:56:03.634594Z",
     "shell.execute_reply": "2024-06-25T10:56:03.654965Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": [
    {
     "execution_count": 21,
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                 row_id  normal_mild  moderate    severe\n0  44036939_spinal_canal_stenosis_l1_l2     0.452616  0.352106  0.195277\n1  44036939_spinal_canal_stenosis_l2_l3     0.197680  0.438134  0.364187\n2  44036939_spinal_canal_stenosis_l3_l4     0.163294  0.327955  0.508751\n3  44036939_spinal_canal_stenosis_l4_l5     0.220444  0.236467  0.543090\n4  44036939_spinal_canal_stenosis_l5_s1     0.819369  0.101085  0.079546",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>normal_mild</th>\n      <th>moderate</th>\n      <th>severe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>44036939_spinal_canal_stenosis_l1_l2</td>\n      <td>0.452616</td>\n      <td>0.352106</td>\n      <td>0.195277</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44036939_spinal_canal_stenosis_l2_l3</td>\n      <td>0.197680</td>\n      <td>0.438134</td>\n      <td>0.364187</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44036939_spinal_canal_stenosis_l3_l4</td>\n      <td>0.163294</td>\n      <td>0.327955</td>\n      <td>0.508751</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44036939_spinal_canal_stenosis_l4_l5</td>\n      <td>0.220444</td>\n      <td>0.236467</td>\n      <td>0.543090</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44036939_spinal_canal_stenosis_l5_s1</td>\n      <td>0.819369</td>\n      <td>0.101085</td>\n      <td>0.079546</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Conclusion\nWe created the dataset, performed training, and inference in this notebook. \n\nThis competition is a bit complicated to handle the dataset, so there may be a better way.\n\nI think there are many other areas to improve in my notebook. I hope you can learn from my notebook and get a better score.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
