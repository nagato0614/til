{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import pydicom as dicom\n",
    "import pydicom\n",
    "import json\n",
    "import glob\n",
    "import collections\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import cv2\n",
    "from skimage import measure\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import plotly.graph_objects as go\n",
    "import random\n",
    "from glob import glob\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import ssl\n",
    "from keras.src.layers import Flatten, Dense, Concatenate\n",
    "from keras import Model, Input\n",
    "from keras.src.utils import to_categorical\n",
    "from keras.callbacks import Callback\n",
    "import gc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# label_coordinates_df = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\n",
    "# train_series = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')\n",
    "# df_train = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\n",
    "# df_sub = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv')\n",
    "# test_series = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv')\n",
    "\n",
    "base_path = '/Volumes/SSD/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "train_png_file_path = f'{base_path}/train_dataset_png'\n",
    "\n",
    "label_coordinates_df = pd.read_csv(f'{base_path}/train_label_coordinates.csv')\n",
    "train_series = pd.read_csv(f'{base_path}/train_series_descriptions.csv')\n",
    "df_train = pd.read_csv(f'{base_path}/train.csv')\n",
    "df_sub = pd.read_csv(f'{base_path}/sample_submission.csv')\n",
    "test_series = pd.read_csv(f'{base_path}/test_series_descriptions.csv')\n",
    "\n",
    "train_dicom = f'{base_path}/train_images'\n",
    "test_dicom = f'{base_path}/test_images'\n",
    "\n",
    "model_path = f'model.keras'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# パラメータ\n",
    "STUDY_NUM = 1975\n",
    "\n",
    "# 出力のラベル\n",
    "NORMAL_MILD = 0\n",
    "MODERATE = 1\n",
    "SEVERE = 2\n",
    "\n",
    "# 重症度一覧\n",
    "SEVERITY_LIST = ['Normal/Mild', 'Moderate', 'Severe']\n",
    "\n",
    "# dicomデータの種類\n",
    "SERIES_DESCRIPTION_LIST = train_series['series_description'].unique().tolist()\n",
    "# 学習用パラメータ\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 50\n",
    "TRAIN_RATIO = 0.8\n",
    "VALID_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "# 入出力の形状\n",
    "INPUT_WIDTH = 512\n",
    "INPUT_HEIGHT = 512\n",
    "INPUT_CHANNEL = 20\n",
    "INPUT_CHANNEL_LIST = [20, 50, 20]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# train_series に画像枚数を表す列を追加\n",
    "train_series['num_images'] = None\n",
    "\n",
    "# 画像枚数を列ごとに追加\n",
    "for i in range(len(train_series)):\n",
    "  study_id = train_series.loc[i, 'study_id']\n",
    "  series_id = train_series.loc[i, 'series_id']\n",
    "  train_dicom_filepath = f'{train_dicom}/{study_id}/{series_id}'\n",
    "  \n",
    "  # train_dicom_filepathに含まれるdicomファイルの数を取得\n",
    "  num_images = len(glob(f'{train_dicom_filepath}/*.dcm'))\n",
    "  train_series.loc[i, 'num_images'] = num_images\n",
    "  \n",
    "# series_desctiopnごとに最大と最小の画像枚数を取得\n",
    "for series_dec in SERIES_DESCRIPTION_LIST:\n",
    "  series_dec_df = train_series[train_series['series_description'] == series_dec]\n",
    "  max_num_images = series_dec_df['num_images'].max()\n",
    "  min_num_images = series_dec_df['num_images'].min()\n",
    "  print(f'{series_dec}: max={max_num_images}, min={min_num_images}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "_target_name = \"right_subarticular_stenosis_l5_s1\"\n",
    "\n",
    "print(f'train shape : {df_train.shape}')\n",
    "print(df_train[_target_name].unique())\n",
    "\n",
    "# それぞれの重症度の数がいくらあるか計算\n",
    "print(f'Normal/Mild : {df_train[df_train[_target_name] == str(\"Normal/Mild\")].shape[0]}')\n",
    "print(f'Moderate : {df_train[df_train[_target_name] == str(\"Moderate\")].shape[0]}')\n",
    "print(f'Severe : {df_train[df_train[_target_name] == str(\"Severe\")].shape[0]}')\n",
    "\n",
    "print(\n",
    "    f'Normal/Mild ratio : {df_train[df_train[_target_name] == str(\"Normal/Mild\")].shape[0] / df_train.shape[0]}')\n",
    "print(\n",
    "    f'Moderate ratio : {df_train[df_train[_target_name] == str(\"Moderate\")].shape[0] / df_train.shape[0]}')\n",
    "print(\n",
    "    f'Severe ratio : {df_train[df_train[_target_name] == str(\"Severe\")].shape[0] / df_train.shape[0]}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
