{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 19:30:16.587715: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 19:30:17.199055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import h5py\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "from keras import Model, Input\n",
    "from keras.src.layers import Dense, Dropout\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.src.callbacks import Callback\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.ops import clip_ops, math_ops\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.src import ops\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_hdf5 = \"train-image.hdf5\"\n",
    "train_metadata_csv = \"train-metadata.csv\"\n",
    "test_image_hdf5 = \"test-image.hdf5\"\n",
    "test_metadata_csv = \"test-metadata.csv\"\n",
    "sample_submission_csv = \"sample_submission.csv\"\n",
    "\n",
    "base_path = \"/kaggle/input/isic-2024-challenge\"\n",
    "model_path = \"/kaggle/input/isic2024_densenet/keras/default/1/model_dense.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"SEED\": 42,\n",
    "    \"N_FOLDS\": 5,\n",
    "    \"N_EPOCHS\": 100,\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"VAL_BATCH_SIZE\": 50,\n",
    "    \"LR\": 0.001,\n",
    "    \"IMAGE_HEIGHT\": 224,\n",
    "    \"IMAGE_WIDTH\": 224,\n",
    "    \"IMAGE_CHANNEL\": 3,\n",
    "    \"N_CLASSES\": 1,\n",
    "    \"PATIENCE\": 2,\n",
    "    \"TRAIN_RATIO\": 0.8,\n",
    "    \"VAL_RATIO\": 0.1,\n",
    "    \"TEST_RATIO\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_346788/1119585719.py:1: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(f\"{base_path}/{train_metadata_csv}\")\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f\"{base_path}/{train_metadata_csv}\")\n",
    "df_test = pd.read_csv(f\"{base_path}/{test_metadata_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_and_label(hdf, isic_id, mode = \"train\"):\n",
    "    # 画像を取得\n",
    "    image_data = hdf[isic_id][()]\n",
    "\n",
    "    # Convert the binary data to a numpy array\n",
    "    image_data = np.frombuffer(image_data, np.uint8)\n",
    "\n",
    "    # Decode the image from the numpy array\n",
    "    image_data = cv2.cvtColor(cv2.imdecode(image_data, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image_data = cv2.resize(image_data, (CONFIG[\"IMAGE_HEIGHT\"], CONFIG[\"IMAGE_WIDTH\"]))\n",
    "\n",
    "    # 画像の正規化 (0 ~ 1) に変換\n",
    "    image_data = (image_data - image_data.min()) / (image_data.max() - image_data.min())\n",
    "    \n",
    "    # クラスを取得する. これが学習時のラベルになる\n",
    "    if mode == \"train\":\n",
    "        label = df_train[df_train[\"isic_id\"] == isic_id][\"target\"].values[0]\n",
    "    elif mode == \"test\":\n",
    "        label = 0\n",
    "    return image_data, label\n",
    "\n",
    "\n",
    "\n",
    "def normalize_image(image):\n",
    "    # 画像の正規化 (0 ~ 1) に変換\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    return image\n",
    "\n",
    "def augmentation(image):\n",
    "    \n",
    "    # 確率で画像をズーム\n",
    "    if np.random.rand() > 0.5:\n",
    "        scale = np.random.uniform(0.8, 1.2)\n",
    "        image = cv2.resize(image, (0, 0), fx=scale, fy=scale)\n",
    "        image = cv2.resize(image, (CONFIG[\"IMAGE_HEIGHT\"], CONFIG[\"IMAGE_WIDTH\"]))\n",
    "    \n",
    "    # 明るさを変える\n",
    "    alpha = 1.0 + np.random.uniform(-0.01, 0.01)\n",
    "    beta = np.random.uniform(-0.01, 0.01)\n",
    "    image = image * alpha + beta\n",
    "    \n",
    "    # 画像をぼかす\n",
    "    k_size = np.random.randint(1, 10) * 2 + 1\n",
    "    image = cv2.GaussianBlur(image, (k_size, k_size), 0)\n",
    "\n",
    "    # 確率で付与するノイズを変える\n",
    "    if np.random.rand() > 0.5:\n",
    "        # ガウシアンノイズ\n",
    "        image = image + np.random.normal(0, 0.1, image.shape)\n",
    "        image = np.clip(image, 0, 1)\n",
    "        \n",
    "    # 画像を確率で反転\n",
    "    if np.random.rand() > 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "\n",
    "    # 特定の範囲を切り抜く\n",
    "    n_cut = np.random.randint(1, 5)\n",
    "    for _ in range(n_cut):\n",
    "        WINDOW_SIZE = np.random.randint(10, 50)\n",
    "        x_min = np.random.randint(0, image.shape[0] - WINDOW_SIZE)\n",
    "        x_max = x_min + WINDOW_SIZE\n",
    "        y_min = np.random.randint(0, image.shape[1] - WINDOW_SIZE)\n",
    "        y_max = y_min + WINDOW_SIZE\n",
    "        image[x_min:x_max, y_min:y_max] = 0\n",
    "\n",
    "    # 画像を回転\n",
    "    angle = np.random.randint(0, 360)\n",
    "    image = cv2.warpAffine(image, cv2.getRotationMatrix2D((image.shape[1] / 2, image.shape[0] / 2), angle, 1.0),\n",
    "                           (image.shape[1], image.shape[0]))\n",
    "\n",
    "    return image\n",
    "\n",
    "def generator(isic_ids,\n",
    "              batch_size=CONFIG[\"BATCH_SIZE\"],\n",
    "              mode=\"train\",\n",
    "              is_augmentation=False,\n",
    "              is_shuffle=False,\n",
    "              is_one_epoch=False,\n",
    "              is_multi_threading=False\n",
    "              ):\n",
    "    hdf_path = None\n",
    "    if mode == \"train\":\n",
    "        hdf_path = f\"{base_path}/{train_image_hdf5}\"\n",
    "    elif mode == \"test\":\n",
    "        hdf_path = f\"{base_path}/{test_image_hdf5}\"\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'train' or 'test'\")\n",
    "    \n",
    "    def process_image_label(isic_id):\n",
    "        with h5py.File(hdf_path, \"r\") as hdf:\n",
    "            image, label = get_image_and_label(hdf, isic_id, mode)\n",
    "            if is_augmentation:\n",
    "                image = augmentation(image)\n",
    "                \n",
    "            # 画像を正規化\n",
    "            image = normalize_image(image)\n",
    "        return image, label\n",
    "\n",
    "    while True:\n",
    "        if is_shuffle:\n",
    "            random.shuffle(isic_ids)\n",
    "\n",
    "        for i in range(0, len(isic_ids), batch_size):\n",
    "            end = min(i + batch_size, len(isic_ids))\n",
    "            batch_isic_ids = isic_ids[i:end]\n",
    "            if is_multi_threading:\n",
    "                with ThreadPoolExecutor() as executor:\n",
    "                    results = list(executor.map(process_image_label, batch_isic_ids))\n",
    "            else:\n",
    "                results = [process_image_label(isic_id) for isic_id in batch_isic_ids]\n",
    "\n",
    "            images, labels = zip(*results)\n",
    "            images = np.array(images)\n",
    "            labels = np.array(labels)\n",
    "\n",
    "            yield images, labels\n",
    "\n",
    "        if is_one_epoch:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float = 0.80):\n",
    "    v_gt = abs(np.asarray(solution.values) - 1)\n",
    "    v_pred = np.array([1.0 - x for x in submission.values])\n",
    "    max_fpr = abs(1 - min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr ** 2 + (max_fpr - 0.5 * max_fpr ** 2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n",
    "\n",
    "\n",
    "def auroc(y_true, y_pred, min_fpr=0.8):\n",
    "    v_gt = tf.abs(y_true - 1)\n",
    "    v_pr = tf.abs(y_pred - 1)\n",
    "    partial_auc_scaled = tf.py_function(comp_score, [v_gt, v_pr], tf.float64)\n",
    "    partial_auc = 0.5 * min_fpr ** 2 + (min_fpr - 0.5 * min_fpr ** 2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n",
    "\n",
    "\n",
    "class AUCROCMetric(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='aucroc', **kwargs):\n",
    "        super(AUCROCMetric, self).__init__(name=name, **kwargs)\n",
    "        self.auc_metric = tf.keras.metrics.AUC()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.auc_metric.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        return self.auc_metric.result()\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.auc_metric.reset_states()\n",
    "\n",
    "def binary_crossentropy_balance(target, output):\n",
    "    # target を output の型にキャスト\n",
    "    target = tf.dtypes.cast(target, output.dtype)\n",
    "    epsilon_ = constant_op.constant(0.00001, output.dtype)\n",
    "\n",
    "    # nan を防ぐためにクリップ\n",
    "    output = clip_ops.clip_by_value(output, epsilon_, 0.99999)\n",
    "\n",
    "    # 交差エントロピーの計算\n",
    "    bce = target * math_ops.log(output + epsilon_) * 3.0\n",
    "    bce += (1.0 - target) * math_ops.log(1.0 - output + epsilon_)\n",
    "\n",
    "    bce_sum = -K.sum(bce, axis=-1)\n",
    "    return bce_sum\n",
    "\n",
    "def create_model(model_name='DenseNet201'):\n",
    "    # カスタム入力層\n",
    "    input_shape = (CONFIG[\"IMAGE_HEIGHT\"], CONFIG[\"IMAGE_WIDTH\"], CONFIG[\"IMAGE_CHANNEL\"])\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # DenseNet201\n",
    "    base_model = tf.keras.applications.DenseNet201(\n",
    "        include_top=True,\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=x,\n",
    "        input_shape=input_shape,\n",
    "        pooling=\"avg\",\n",
    "        classes=1000,\n",
    "        classifier_activation='softmax',\n",
    "    )\n",
    "\n",
    "    # ベースモデルの出力\n",
    "    x = base_model.output\n",
    "    x = Dense(1000, activation='sigmoid')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # モデルの作成\n",
    "    model = Model(inputs=inputs, outputs=x, name=model_name)\n",
    "\n",
    "    # optimizer : Adam\n",
    "    opt = tf.keras.optimizers.AdamW(learning_rate=CONFIG[\"LR\"])\n",
    "\n",
    "    # モデルのコンパイル\n",
    "    model.compile(optimizer=opt, loss=binary_crossentropy_balance, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "# モデルの概要を表示\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを読み込み\n",
    "model = tf.keras.models.load_model(model_path, custom_objects={'binary_crossentropy_balance': binary_crossentropy_balance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721558028.862731  346871 service.cc:145] XLA service 0x7da714003dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721558028.862770  346871 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 SUPER, Compute Capability 7.5\n",
      "2024-07-21 19:33:49.135154: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-21 19:33:50.279549: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721558037.337685  346871 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "test_ids = df_test[\"isic_id\"].values\n",
    "# テストデータの予測\n",
    "y_pred = model.predict(\n",
    "    generator(test_ids, \n",
    "              mode=\"test\",\n",
    "              is_augmentation=False,\n",
    "              is_shuffle=False, \n",
    "              is_one_epoch=True,\n",
    "              batch_size=1,\n",
    "              ),\n",
    "    steps=len(test_ids)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用のデータフレームを作成\n",
    "submission = pd.DataFrame()\n",
    "submission[\"isic_id\"] = test_ids.reshape(-1)\n",
    "submission[\"target\"] = y_pred\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.185343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.185343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.185343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id    target\n",
       "0  ISIC_0015657  0.185343\n",
       "1  ISIC_0015729  0.185343\n",
       "2  ISIC_0015740  0.185343"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
